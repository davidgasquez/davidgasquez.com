---
title: "Gitcoin Data Portal"
date: 2023-09-11
slug: gitcoin-data
---

Last week, I went on a rabbit hole after coming across [RegenData.xyz](https://gov.gitcoin.co/t/regendata-xyz-our-sybil-resistant-future-q3-2023-and-beyond/16474), an initiative to collect and surface grants data.

This is very similar to the work I've been doing at Protocol Labs with the [Filecoin Data Portal](https://github.com/davidgasquez/filecoin-data-portal). A fully open source and local friendly data hub for Filecoin related data. Think of Dune, but in your laptop! All based in the [ideas I started exploring with Datadex a while back](https://github.com/davidgasquez/datadex).

I decided to take a stab at building a similar data portal for Gitcoin Grant data that is being exposed via the [Indexer Grants Stack Data API](https://indexer-grants-stack.gitcoin.co/data/). Let's see!

## Exploring the Data

Before jumping into the portal itself, I wanted to see the data and the format it was being exposed. Started by downloading the data generated by the [Allo Indexer](https://github.com/gitcoinco/allo-indexer/). It was a bit slow as Contributors' data is stored as nested partitioned folders based on the contributor's wallet. That makes it very hard to walk and download with things like `wget`.

The best solution I found was to use `lftp`. More specifically, `lftp -c 'mirror --parallel=200 https://indexer-grants-stack.gitcoin.co/data/1/ ;exit'`.

Is not the fastest thing in the world as it has to paginate through all the folders, but will download all the data available to our machine!

Now is a matter of joining JSONs locally with commands like `cat */rounds/*/votes.json | jq .[] -c > round_votes.json` and running some SQL queries on top of them with DuckDB.

The main takeaways (which could probably derived from the code) are:

- Data is very denormalized. We can rebuild most of the JSON files. For example, the tricky `contributors/*` folders is not needed at all as they can be reconstructed from other data sources.
- There is lots of tests data. We should filter it out downstream. Right now, I'm not going to take care of it.

## The Data Portal

<div class="github-card" data-github="davidgasquez/gitcoin-grants-data-portal" data-width="650" data-height="" data-theme="default"></div>
<script src="//cdn.jsdelivr.net/github-cards/latest/widget.js"></script>

Since I already worked on the Filecoin Data Portal, I went with the same approach, reuse the Datadex ideas and stack. That is, Python with Dagster for the ETLs, dbt for the transformations, DuckDB as the database, and Notebooks/Quarto as the frontend.

The first thing was to created the [relevant Dagster assets](https://github.com/davidgasquez/gitcoin-grants-data-portal/blob/main/ggdp/assets.py). These act as the _extract_ and _load_ part of the pipeline and are [later _transformed_ by `dbt` with SQL queries](https://github.com/davidgasquez/gitcoin-grants-data-portal/blob/main/dbt/models/round_votes.sql). Saving both the rawest data and the transformations allows anyone to reuse either the raw data source or the transformed data source!
